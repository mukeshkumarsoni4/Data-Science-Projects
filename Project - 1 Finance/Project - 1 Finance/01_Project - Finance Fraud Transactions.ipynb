{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f6af33",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b9cb7",
   "metadata": {},
   "source": [
    "One of the most critical issues that the finance sector faces is fraud. The fraud impacts the bottom line of a financial institution. It is estimated that a typical financial institution loses  of its revenue to fraud. If we apply this estimate to the Gross World Product of $79.6, the global loss during 2017 was $4 trillion (more than the GDP of India)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b919f0e6",
   "metadata": {},
   "source": [
    "Machine learning models can detect such Fraud. The machine learning models can detect anomalies in the transactions and detect cases that might be prone to fraud. The machine learning models can compute faster as compared to the traditional rule-based approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f17e4",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b94ef4",
   "metadata": {},
   "source": [
    "Define Research Goals\n",
    "The goal of the project is to detect whether a transaction is a normal payment or a fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7693fa",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f34c3",
   "metadata": {},
   "source": [
    "The dataset contains two-day transactions by European cardholders during September 2013.\n",
    "\n",
    "The dataset contains 284,807 transactions out of which 492 were fraud cases\n",
    "\n",
    "Due to the privacy reasons, the dataset has been anonymized. The feature names have also been changed (V1, V2, V3, etc.). Hence, you will not gain much insights from visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc708e1d",
   "metadata": {},
   "source": [
    "## Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0712257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea304cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2815ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec5e1e",
   "metadata": {},
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a1273f",
   "metadata": {},
   "source": [
    "1. View the raw data\n",
    "2. Dimensions of the dataset\n",
    "3. Data Types of the attributes\n",
    "4. Presence of Null Values in the dataset\n",
    "5. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debac418",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2223ff90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7        V8        V9  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  0.363787   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102 -0.255425   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676 -1.514654   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436 -1.387024   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  0.817739   \n",
       "\n",
       "   ...       V21       V22       V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0  ... -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "\n",
       "   Class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5727b361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9124ca",
   "metadata": {},
   "source": [
    "We get the dimension of the dataset. The dataset has 284,807 rows and 31 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348fb3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601f82e",
   "metadata": {},
   "source": [
    "# Our observations are as follows\n",
    "\n",
    "NaN values do not present in the data set. Because of the Non-Null Count and number of rows in the dataset match.\n",
    "There are 29 Input Variables and 1 Output Variable (Class)\n",
    "The data type of all the input variables is float64 whereas the data type of out variable (Class) is int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c713228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a756c98",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e66671",
   "metadata": {},
   "source": [
    "## Statistical Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7acc67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f89ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4            V5  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15  9.604066e-16   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
       "\n",
       "                 V6            V7            V8            V9  ...           V21           V22  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  ...  2.848070e+05  2.848070e+05   \n",
       "mean   1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15  ...  1.654067e-16 -3.568593e-16   \n",
       "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  ...  7.345240e-01  7.257016e-01   \n",
       "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01  ... -3.483038e+01 -1.093314e+01   \n",
       "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01  ... -2.283949e-01 -5.423504e-01   \n",
       "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02  ... -2.945017e-02  6.781943e-03   \n",
       "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  ...  1.863772e-01  5.285536e-01   \n",
       "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  ...  2.720284e+01  1.050309e+01   \n",
       "\n",
       "                V23           V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   2.578648e-16  4.473266e-15  5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16   \n",
       "std    6.244603e-01  6.056471e-01  5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01   \n",
       "min   -4.480774e+01 -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01   \n",
       "25%   -1.618463e-01 -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02   \n",
       "50%   -1.119293e-02  4.097606e-02  1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02   \n",
       "75%    1.476421e-01  4.395266e-01  3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02   \n",
       "max    2.252841e+01  4.584549e+00  7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   \n",
       "\n",
       "              Amount          Class  \n",
       "count  284807.000000  284807.000000  \n",
       "mean       88.349619       0.001727  \n",
       "std       250.120109       0.041527  \n",
       "min         0.000000       0.000000  \n",
       "25%         5.600000       0.000000  \n",
       "50%        22.000000       0.000000  \n",
       "75%        77.165000       0.000000  \n",
       "max     25691.160000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661cdbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.239053e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.673327e-15</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.247012e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.190001e-16</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.207294e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.887456e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.437716e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.772171e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.564149e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.039917e-15</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>6.406204e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%           50%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000  84692.000000   \n",
       "V1      284807.0  1.168375e-15      1.958696  -56.407510     -0.920373      0.018109   \n",
       "V2      284807.0  3.416908e-16      1.651309  -72.715728     -0.598550      0.065486   \n",
       "V3      284807.0 -1.379537e-15      1.516255  -48.325589     -0.890365      0.179846   \n",
       "V4      284807.0  2.074095e-15      1.415869   -5.683171     -0.848640     -0.019847   \n",
       "V5      284807.0  9.604066e-16      1.380247 -113.743307     -0.691597     -0.054336   \n",
       "V6      284807.0  1.487313e-15      1.332271  -26.160506     -0.768296     -0.274187   \n",
       "V7      284807.0 -5.556467e-16      1.237094  -43.557242     -0.554076      0.040103   \n",
       "V8      284807.0  1.213481e-16      1.194353  -73.216718     -0.208630      0.022358   \n",
       "V9      284807.0 -2.406331e-15      1.098632  -13.434066     -0.643098     -0.051429   \n",
       "V10     284807.0  2.239053e-15      1.088850  -24.588262     -0.535426     -0.092917   \n",
       "V11     284807.0  1.673327e-15      1.020713   -4.797473     -0.762494     -0.032757   \n",
       "V12     284807.0 -1.247012e-15      0.999201  -18.683715     -0.405571      0.140033   \n",
       "V13     284807.0  8.190001e-16      0.995274   -5.791881     -0.648539     -0.013568   \n",
       "V14     284807.0  1.207294e-15      0.958596  -19.214325     -0.425574      0.050601   \n",
       "V15     284807.0  4.887456e-15      0.915316   -4.498945     -0.582884      0.048072   \n",
       "V16     284807.0  1.437716e-15      0.876253  -14.129855     -0.468037      0.066413   \n",
       "V17     284807.0 -3.772171e-16      0.849337  -25.162799     -0.483748     -0.065676   \n",
       "V18     284807.0  9.564149e-16      0.838176   -9.498746     -0.498850     -0.003636   \n",
       "V19     284807.0  1.039917e-15      0.814041   -7.213527     -0.456299      0.003735   \n",
       "V20     284807.0  6.406204e-16      0.770925  -54.497720     -0.211721     -0.062481   \n",
       "V21     284807.0  1.654067e-16      0.734524  -34.830382     -0.228395     -0.029450   \n",
       "V22     284807.0 -3.568593e-16      0.725702  -10.933144     -0.542350      0.006782   \n",
       "V23     284807.0  2.578648e-16      0.624460  -44.807735     -0.161846     -0.011193   \n",
       "V24     284807.0  4.473266e-15      0.605647   -2.836627     -0.354586      0.040976   \n",
       "V25     284807.0  5.340915e-16      0.521278  -10.295397     -0.317145      0.016594   \n",
       "V26     284807.0  1.683437e-15      0.482227   -2.604551     -0.326984     -0.052139   \n",
       "V27     284807.0 -3.660091e-16      0.403632  -22.565679     -0.070840      0.001342   \n",
       "V28     284807.0 -1.227390e-16      0.330083  -15.430084     -0.052960      0.011244   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000     22.000000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000      0.000000   \n",
       "\n",
       "                  75%            max  \n",
       "Time    139320.500000  172792.000000  \n",
       "V1           1.315642       2.454930  \n",
       "V2           0.803724      22.057729  \n",
       "V3           1.027196       9.382558  \n",
       "V4           0.743341      16.875344  \n",
       "V5           0.611926      34.801666  \n",
       "V6           0.398565      73.301626  \n",
       "V7           0.570436     120.589494  \n",
       "V8           0.327346      20.007208  \n",
       "V9           0.597139      15.594995  \n",
       "V10          0.453923      23.745136  \n",
       "V11          0.739593      12.018913  \n",
       "V12          0.618238       7.848392  \n",
       "V13          0.662505       7.126883  \n",
       "V14          0.493150      10.526766  \n",
       "V15          0.648821       8.877742  \n",
       "V16          0.523296      17.315112  \n",
       "V17          0.399675       9.253526  \n",
       "V18          0.500807       5.041069  \n",
       "V19          0.458949       5.591971  \n",
       "V20          0.133041      39.420904  \n",
       "V21          0.186377      27.202839  \n",
       "V22          0.528554      10.503090  \n",
       "V23          0.147642      22.528412  \n",
       "V24          0.439527       4.584549  \n",
       "V25          0.350716       7.519589  \n",
       "V26          0.240952       3.517346  \n",
       "V27          0.091045      31.612198  \n",
       "V28          0.078280      33.847808  \n",
       "Amount      77.165000   25691.160000  \n",
       "Class        0.000000       1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf15976",
   "metadata": {},
   "source": [
    "We can see that the data for the variables from V1 to V28 is already scaled and cleaned. So there is no need for a data cleaning process in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612d582",
   "metadata": {},
   "source": [
    "## Response Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24adcd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_name = {0: 'Not Fraud', 1: 'Fraud'}\n",
    "print(fraud_data.Class.value_counts().rename(index = class_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b09a3",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db9c5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88e0a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fraud_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b836de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fraud_data.loc[:, fraud_data.columns != 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d68592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe3b02",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0526e",
   "metadata": {},
   "source": [
    "Linear Algorithms\n",
    "\n",
    "Logistic Regression (LR) and Linear Discriminant Analysis(LDA)\n",
    "\n",
    "Non-Linear Algorithms\n",
    "\n",
    "Classification and Regression Tree (CART) and K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e04d3",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b46fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd03910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f305f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bc4e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd661d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logisreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e79bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logisreg = round(accuracy_score(y_test, y_pred) * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1f7312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model :  99.91\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression model : ', acc_logisreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b311ca",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99b04f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "757a3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f23d15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ed6a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63ccc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lda = round(accuracy_score(y_test, y_pred) * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c53e286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear Discriminant Analysis Classifier :  99.93\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Linear Discriminant Analysis Classifier : ', acc_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533dbf38",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdc8cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a894a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d59efd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea164f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bbe65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ganb = round(accuracy_score(y_test, y_pred)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6354abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes :  99.28\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Gaussian Naive Bayes : ', acc_ganb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b043ba",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b227330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af8bfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d56279d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba903bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7afb5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dtree = round(accuracy_score(y_test, y_pred)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5829dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier :  99.92\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree Classifier : ', acc_dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34620f8c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "168ae4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f9082d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17da83a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aaddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "060f9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf = round( accuracy_score(y_test, y_pred) * 100, 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bee7b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Random Forest :  99.96\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy of  Random Forest : ', acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26946837",
   "metadata": {},
   "source": [
    "## Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31ef7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b6637fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99fe4606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "528cb918",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33f18da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svc = round( accuracy_score(y_test, y_pred) * 100, 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09cf7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Support Vector Classifier:  99.83\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy of  Support Vector Classifier: ', acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68397f3e",
   "metadata": {},
   "source": [
    "## K Nearest Neighbour Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7a4e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6b8d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9af46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7b84be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcfe9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = round( accuracy_score(y_test, y_pred) * 100, 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b53c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  KNN Classifier:  99.83\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy of  KNN Classifier: ', acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5307004",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0875514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Linear Discriminant Analysis','Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines', \n",
    "              'K - Nearest Neighbors'],\n",
    "    'Score': [acc_logisreg, acc_lda, acc_ganb, acc_dtree, acc_rf, acc_svc, acc_knn]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0685e3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>99.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>99.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>99.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K - Nearest Neighbors</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>99.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Score\n",
       "4                 Random Forest  99.96\n",
       "1  Linear Discriminant Analysis  99.93\n",
       "3                 Decision Tree  99.92\n",
       "0           Logistic Regression  99.91\n",
       "5       Support Vector Machines  99.83\n",
       "6         K - Nearest Neighbors  99.83\n",
       "2                   Naive Bayes  99.28"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb90d2b",
   "metadata": {},
   "source": [
    "We can select the Random Forest as it has given us the maximum accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84300d3",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa5c8a",
   "metadata": {},
   "source": [
    "ACCURACY\n",
    "\n",
    "Accuracy is the ratio of correct predictions made and all the predictions made. This is the most common evaluation metric for classification problems. However, it is also the most misused. We should use accuracy when there is an equal number of observations in each class (which is rarely the case) and when all predictions and the related prediction errors are equally important, which is often not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a81f98",
   "metadata": {},
   "source": [
    "PRECISION\n",
    "\n",
    "Precision is the percentage of positive instances out of the total predicted positive instances. Here, the denominator is the model prediction done as positive from the whole given dataset. Precision is a good measure to determine when the cost of false positives is high (e.g., email spam detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a5c76",
   "metadata": {},
   "source": [
    "RECALL\n",
    "\n",
    "Recall (or sensitivity or true positive rate) is the percentage of positive instances out of the total actual positive instances. Therefore, the denominator (true positive + false negative) is the actual number of positive instances present in the dataset. The recall is a good measure when there is a high cost associated with false negatives (e.g., fraud detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "811549d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "addff174",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0327dce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94772,     0],\n",
       "       [  164,     0]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f59eaec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28f4ccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f44c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d15590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
